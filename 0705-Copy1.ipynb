{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4acdfa",
   "metadata": {},
   "source": [
    "### 库导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc12b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from scipy import signal\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ce762",
   "metadata": {},
   "source": [
    "### 随机抽取一个正样本一个负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a109d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_samples(positive_file, negative_file):\n",
    "    with open(positive_file, 'r') as f:\n",
    "        positive_samples = f.readlines()\n",
    "    with open(negative_file, 'r') as f:\n",
    "        negative_samples = f.readlines()\n",
    "    \n",
    "    positive_index = random.randint(0, len(positive_samples)//4) * 4\n",
    "    negative_index = random.randint(0, len(negative_samples)//4) * 4\n",
    "    \n",
    "    positive_sample = positive_samples[positive_index:positive_index+4]\n",
    "    negative_sample = negative_samples[negative_index:negative_index+4]\n",
    "    \n",
    "    # 提取文件名和时间信息\n",
    "    positive_file_name = positive_sample[0].split(': ')[1].strip()\n",
    "    positive_start_time = int(positive_sample[1].split(': ')[1].strip())\n",
    "    positive_end_time = int(positive_sample[2].split(': ')[1].strip())\n",
    "\n",
    "    negative_file_name = negative_sample[0].split(': ')[1].strip()\n",
    "    negative_start_time = int(negative_sample[1].split(': ')[1].strip())\n",
    "    negative_end_time = int(negative_sample[2].split(': ')[1].strip())\n",
    "    \n",
    "    return positive_file_name, positive_start_time, positive_end_time, negative_file_name, negative_start_time, negative_end_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977317aa",
   "metadata": {},
   "source": [
    "### 读取和可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572efff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_visualize_samples(positive_file, negative_file, data_positive_folder, data_negative_folder):\n",
    "    # 获取正样本和负样本的文件名和时间点\n",
    "    positive_file_name, positive_start_time, positive_end_time, negative_file_name, negative_start_time, negative_end_time = get_random_samples(positive_file, negative_file)\n",
    "\n",
    "    # 显示正样本和负样本的文件名和时间点\n",
    "    print(\"Positive Sample:\")\n",
    "    print(\"File Name:\", positive_file_name)\n",
    "    print(\"Start Time:\", positive_start_time)\n",
    "    print(\"End Time:\", positive_end_time)\n",
    "    print()\n",
    "    print(\"Negative Sample:\")\n",
    "    print(\"File Name:\", negative_file_name)\n",
    "    print(\"Start Time:\", negative_start_time)\n",
    "    print(\"End Time:\", negative_end_time)\n",
    "    print()\n",
    "\n",
    "    # 读取正样本和负样本的数据\n",
    "    positive_data_file = os.path.join(data_positive_folder, positive_file_name)\n",
    "    negative_data_file = os.path.join(data_negative_folder, negative_file_name)\n",
    "\n",
    "    positive_raw = mne.io.read_raw_edf(positive_data_file)\n",
    "    negative_raw = mne.io.read_raw_edf(negative_data_file)\n",
    "\n",
    "    # 使用raw.plot函数可视化数据\n",
    "    positive_raw.plot()\n",
    "    negative_raw.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1514c",
   "metadata": {},
   "source": [
    "### 调用读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce57357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sample:\n",
      "File Name: chb19_28.edf\n",
      "Start Time: 335\n",
      "End Time: 341\n",
      "\n",
      "Negative Sample:\n",
      "File Name: chb14_20.edf\n",
      "Start Time: 696\n",
      "End Time: 702\n",
      "\n",
      "Extracting EDF parameters from D:\\Epilepsy\\data_positive_original\\chb19_28.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from D:\\Epilepsy\\data_negative_original\\chb14_20.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Using matplotlib as 2D backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Litchi\\AppData\\Local\\Temp\\ipykernel_8492\\2708482990.py:21: RuntimeWarning: Channel names are not unique, found duplicates for: {'-', 'T8-P8'}. Applying running numbers for duplicates.\n",
      "  positive_raw = mne.io.read_raw_edf(positive_data_file)\n",
      "C:\\Users\\Litchi\\AppData\\Local\\Temp\\ipykernel_8492\\2708482990.py:21: RuntimeWarning: Scaling factor is not defined in following channels:\n",
      "--0, --1, --2, --3, --4\n",
      "  positive_raw = mne.io.read_raw_edf(positive_data_file)\n",
      "C:\\Users\\Litchi\\AppData\\Local\\Temp\\ipykernel_8492\\2708482990.py:22: RuntimeWarning: Channel names are not unique, found duplicates for: {'-', 'T8-P8'}. Applying running numbers for duplicates.\n",
      "  negative_raw = mne.io.read_raw_edf(negative_data_file)\n",
      "C:\\Users\\Litchi\\AppData\\Local\\Temp\\ipykernel_8492\\2708482990.py:22: RuntimeWarning: Scaling factor is not defined in following channels:\n",
      "--0, --1, --2, --3, --4\n",
      "  negative_raw = mne.io.read_raw_edf(negative_data_file)\n"
     ]
    }
   ],
   "source": [
    "data_positive_folder = 'D:/Epilepsy/data_positive_original'\n",
    "data_negative_folder = 'D:/Epilepsy/data_negative_original'\n",
    "positive_file = 'combined_positive.txt'\n",
    "negative_file = 'combined_negative.txt'\n",
    "\n",
    "load_and_visualize_samples(positive_file, negative_file, data_positive_folder, data_negative_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3669c5e7",
   "metadata": {},
   "source": [
    "### 低通滤波"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9bab66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import mne\n",
    "\n",
    "def load_and_filter_samples(positive_file, negative_file, data_positive_folder, data_negative_folder, filtered_positive_folder, filtered_negative_folder):\n",
    "    # 获取正样本和负样本的文件名和时间点\n",
    "    positive_file_name, positive_start_time, positive_end_time, negative_file_name, negative_start_time, negative_end_time = get_random_samples(positive_file, negative_file)\n",
    "\n",
    "    # 显示正样本和负样本的文件名和时间点\n",
    "    print(\"Positive Sample:\")\n",
    "    print(\"File Name:\", positive_file_name)\n",
    "    print(\"Start Time:\", positive_start_time)\n",
    "    print(\"End Time:\", positive_end_time)\n",
    "    print()\n",
    "    print(\"Negative Sample:\")\n",
    "    print(\"File Name:\", negative_file_name)\n",
    "    print(\"Start Time:\", negative_start_time)\n",
    "    print(\"End Time:\", negative_end_time)\n",
    "    print()\n",
    "\n",
    "    # 读取正样本和负样本的数据\n",
    "    positive_data_file = os.path.join(data_positive_folder, positive_file_name)\n",
    "    negative_data_file = os.path.join(data_negative_folder, negative_file_name)\n",
    "\n",
    "    positive_raw = mne.io.read_raw_edf(positive_data_file, preload=True)\n",
    "    negative_raw = mne.io.read_raw_edf(negative_data_file, preload=True)\n",
    "\n",
    "    # 截取\n",
    "    positive_crop = positive_raw.copy().crop(positive_start_time, positive_end_time)\n",
    "    negative_crop = negative_raw.copy().crop(negative_start_time, negative_end_time)\n",
    "    \n",
    "    # 滤波\n",
    "    fs = positive_crop.info['sfreq']\n",
    "    lowcut = 0.01\n",
    "    highcut = 32\n",
    "\n",
    "    # 设计四阶Butterworth滤波器\n",
    "    b, a = signal.butter(4, [lowcut, highcut], btype='band', fs=fs)\n",
    "    \n",
    "    # 应用滤波器\n",
    "    positive_filtered_data = signal.filtfilt(b, a, positive_crop.get_data())\n",
    "    negative_filtered_data = signal.filtfilt(b, a, negative_crop.get_data())\n",
    "    \n",
    "   # 保存滤波后的样本\n",
    "    positive_file_base = os.path.basename(positive_data_file).replace('.edf', '')\n",
    "    negative_file_base = os.path.basename(negative_data_file).replace('.edf', '')\n",
    "    positive_save_name = f\"{positive_file_base}_{positive_start_time}_filtered.npy\"\n",
    "    negative_save_name = f\"{negative_file_base}_{negative_start_time}_filtered.npy\"\n",
    "    \n",
    "    filtered_positive_file = os.path.join(filtered_positive_folder, positive_save_name)\n",
    "    filtered_negative_file = os.path.join(filtered_negative_folder, negative_save_name)\n",
    "\n",
    "    np.save(filtered_positive_file, positive_filtered_data)\n",
    "    np.save(filtered_negative_file, negative_filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d8f597",
   "metadata": {},
   "source": [
    "### 循环调用N次读取并滤波 得到N个正负样本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c616f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sample:\n",
      "File Name: chb05_16.edf\n",
      "Start Time: 2401\n",
      "End Time: 2407\n",
      "\n",
      "Negative Sample:\n",
      "File Name: chb22_17.edf\n",
      "Start Time: 2856\n",
      "End Time: 2862\n",
      "\n",
      "Extracting EDF parameters from D:\\Epilepsy\\data_positive_original\\chb05_16.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Litchi\\AppData\\Local\\Temp\\ipykernel_8492\\220387253.py:26: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  positive_raw = mne.io.read_raw_edf(positive_data_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Epilepsy\\data_negative_original\\chb22_17.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Litchi\\AppData\\Local\\Temp\\ipykernel_8492\\220387253.py:27: RuntimeWarning: Channel names are not unique, found duplicates for: {'-', 'T8-P8'}. Applying running numbers for duplicates.\n",
      "  negative_raw = mne.io.read_raw_edf(negative_data_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sample:\n",
      "File Name: chb14_04.edf\n",
      "Start Time: 2823\n",
      "End Time: 2829\n",
      "\n",
      "Negative Sample:\n",
      "File Name: chb20_21.edf\n",
      "Start Time: 0\n",
      "End Time: 6\n",
      "\n",
      "Extracting EDF parameters from D:\\Epilepsy\\data_positive_original\\chb14_04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Litchi\\AppData\\Local\\Temp\\ipykernel_8492\\220387253.py:26: RuntimeWarning: Channel names are not unique, found duplicates for: {'-', 'T8-P8'}. Applying running numbers for duplicates.\n",
      "  positive_raw = mne.io.read_raw_edf(positive_data_file, preload=True)\n",
      "C:\\Users\\Litchi\\AppData\\Local\\Temp\\ipykernel_8492\\220387253.py:26: RuntimeWarning: Scaling factor is not defined in following channels:\n",
      "--0, --1, --2, --3, --4\n",
      "  positive_raw = mne.io.read_raw_edf(positive_data_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\Epilepsy\\data_negative_original\\chb20_21.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 926207  =      0.000 ...  3617.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Litchi\\AppData\\Local\\Temp\\ipykernel_8492\\220387253.py:27: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8', '.'}. Applying running numbers for duplicates.\n",
      "  negative_raw = mne.io.read_raw_edf(negative_data_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sample:\n",
      "File Name: chb07_19.edf\n",
      "Start Time: 13700\n",
      "End Time: 13706\n",
      "\n",
      "Negative Sample:\n",
      "File Name: chb02_23.edf\n",
      "Start Time: 1218\n",
      "End Time: 1224\n",
      "\n",
      "Extracting EDF parameters from D:\\Epilepsy\\data_positive_original\\chb07_19.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 3689215  =      0.000 ... 14410.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Litchi\\AppData\\Local\\Temp\\ipykernel_8492\\220387253.py:26: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  positive_raw = mne.io.read_raw_edf(positive_data_file, preload=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# 指定循环次数N\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mload_and_filter_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_positive_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_negative_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_positive_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_negative_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m, in \u001b[0;36mload_and_filter_samples\u001b[1;34m(positive_file, negative_file, data_positive_folder, data_negative_folder, filtered_positive_folder, filtered_negative_folder)\u001b[0m\n\u001b[0;32m     23\u001b[0m positive_data_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_positive_folder, positive_file_name)\n\u001b[0;32m     24\u001b[0m negative_data_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_negative_folder, negative_file_name)\n\u001b[1;32m---> 26\u001b[0m positive_raw \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_raw_edf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_data_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m negative_raw \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_raw_edf(negative_data_file, preload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 截取\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\python3.11.3\\Lib\\site-packages\\mne\\io\\edf\\edf.py:1588\u001b[0m, in \u001b[0;36mread_raw_edf\u001b[1;34m(input_fname, eog, misc, stim_channel, exclude, infer_types, include, preload, units, encoding, verbose)\u001b[0m\n\u001b[0;32m   1586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1587\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly EDF files are supported, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRawEDF\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_fname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_fname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1590\u001b[0m \u001b[43m    \u001b[49m\u001b[43meog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmisc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmisc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstim_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstim_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1594\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1597\u001b[0m \u001b[43m    \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1600\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<decorator-gen-253>:12\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, verbose)\u001b[0m\n",
      "File \u001b[1;32mD:\\Python\\python3.11.3\\Lib\\site-packages\\mne\\io\\edf\\edf.py:181\u001b[0m, in \u001b[0;36mRawEDF.__init__\u001b[1;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, verbose)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Raw attributes\u001b[39;00m\n\u001b[0;32m    180\u001b[0m last_samps \u001b[38;5;241m=\u001b[39m [edf_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnsamples\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minput_fname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_extras\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43medf_info\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlast_samps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_samps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43morig_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43morig_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Read annotations from file and set it\u001b[39;00m\n\u001b[0;32m    193\u001b[0m onset, duration, desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n",
      "File \u001b[1;32m<decorator-gen-231>:12\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, info, preload, first_samps, last_samps, filenames, raw_extras, orig_format, dtype, buffer_size_sec, orig_units, verbose)\u001b[0m\n",
      "File \u001b[1;32mD:\\Python\\python3.11.3\\Lib\\site-packages\\mne\\io\\base.py:291\u001b[0m, in \u001b[0;36mBaseRaw.__init__\u001b[1;34m(self, info, preload, first_samps, last_samps, filenames, raw_extras, orig_format, dtype, buffer_size_sec, orig_units, verbose)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# If we have True or a string, actually do the preloading\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_from_disk:\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_kwargs \u001b[38;5;241m=\u001b[39m _get_argvalues()\n",
      "File \u001b[1;32mD:\\Python\\python3.11.3\\Lib\\site-packages\\mne\\io\\base.py:586\u001b[0m, in \u001b[0;36mBaseRaw._preload_data\u001b[1;34m(self, preload)\u001b[0m\n\u001b[0;32m    581\u001b[0m     data_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    582\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m ... \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m  =  \u001b[39m\u001b[38;5;132;01m%9.3f\u001b[39;00m\u001b[38;5;124m ... \u001b[39m\u001b[38;5;132;01m%9.3f\u001b[39;00m\u001b[38;5;124m secs...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimes) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    585\u001b[0m )\n\u001b[1;32m--> 586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnchan\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m<decorator-gen-233>:12\u001b[0m, in \u001b[0;36m_read_segment\u001b[1;34m(self, start, stop, sel, data_buffer, verbose)\u001b[0m\n",
      "File \u001b[1;32mD:\\Python\\python3.11.3\\Lib\\site-packages\\mne\\io\\base.py:462\u001b[0m, in \u001b[0;36mBaseRaw._read_segment\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# reindex back to original file\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     orig_idx \u001b[38;5;241m=\u001b[39m _convert_slice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_picks[fi][need_idx])\n\u001b[1;32m--> 462\u001b[0m     \u001b[43m_ReadSegmentFileProtector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_segment_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis_sl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43morig_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstop_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m     offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m n_read\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mD:\\Python\\python3.11.3\\Lib\\site-packages\\mne\\io\\base.py:2514\u001b[0m, in \u001b[0;36m_ReadSegmentFileProtector._read_segment_file\u001b[1;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[0;32m   2513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_segment_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, idx, fi, start, stop, cals, mult):\n\u001b[1;32m-> 2514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_segment_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2515\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmult\u001b[49m\n\u001b[0;32m   2516\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\python3.11.3\\Lib\\site-packages\\mne\\io\\edf\\edf.py:219\u001b[0m, in \u001b[0;36mRawEDF._read_segment_file\u001b[1;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_segment_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, idx, fi, start, stop, cals, mult):\n\u001b[0;32m    218\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read a chunk of raw data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_segment_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_extras\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filenames\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\python3.11.3\\Lib\\site-packages\\mne\\io\\edf\\edf.py:390\u001b[0m, in \u001b[0;36m_read_segment_file\u001b[1;34m(data, idx, fi, start, stop, raw_extras, filenames, cals, mult)\u001b[0m\n\u001b[0;32m    388\u001b[0m fid\u001b[38;5;241m.\u001b[39mseek(start_offset \u001b[38;5;241m+\u001b[39m block_offset, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m# Read and reshape to (n_chunks_read, ch0_ch1_ch2_ch3...)\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m many_chunk \u001b[38;5;241m=\u001b[39m \u001b[43m_read_ch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch_offsets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_byte\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(n_read, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    393\u001b[0m r_sidx \u001b[38;5;241m=\u001b[39m r_lims[ai][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    394\u001b[0m r_eidx \u001b[38;5;241m=\u001b[39m buf_len \u001b[38;5;241m*\u001b[39m (n_read \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m r_lims[ai \u001b[38;5;241m+\u001b[39m n_read \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mD:\\Python\\python3.11.3\\Lib\\site-packages\\mne\\io\\edf\\edf.py:346\u001b[0m, in \u001b[0;36m_read_ch\u001b[1;34m(fid, subtype, samp, dtype_byte, dtype)\u001b[0m\n\u001b[0;32m    342\u001b[0m     ch_data[ch_data \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m23\u001b[39m)] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m24\u001b[39m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# GDF data and EDF data\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m     ch_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ch_data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_positive_folder = 'D:/Epilepsy/data_positive_original'\n",
    "data_negative_folder = 'D:/Epilepsy/data_negative_original'\n",
    "positive_file = 'combined_positive.txt'\n",
    "negative_file = 'combined_negative.txt'\n",
    "filtered_positive_folder = r'D:\\Epilepsy\\filtered_positive'\n",
    "filtered_negative_folder = r'D:\\Epilepsy\\filtered_negative'\n",
    "num_iterations = 100  # 指定循环次数N\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    load_and_filter_samples(positive_file, negative_file, data_positive_folder, data_negative_folder, filtered_positive_folder, filtered_negative_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7994ead7",
   "metadata": {},
   "source": [
    "### 特征提取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba68019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import pywt\n",
    "import math\n",
    "import nolds\n",
    "from pyentrp import entropy as ent\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "#time domain  \n",
    "def min_X(X):\n",
    "    return np.min(X)\n",
    "\n",
    "def max_X(X):\n",
    "    return np.max(X)\n",
    "\n",
    "def std_X(X):\n",
    "    return np.std(X)\n",
    "\n",
    "def mean_X(X):\n",
    "    return np.mean(X)\n",
    "\n",
    "def var_X(X):\n",
    "    return np.var(X)\n",
    "\n",
    "def totalVariation(X):\n",
    "    Max = np.max(X)\n",
    "    Min = np.min(X)\n",
    "    return np.sum(np.abs(np.diff(X)))/((Max-Min)*(len(X)-1))\n",
    "\n",
    "#偏度用来度量分布是否对称。正态分布左右是对称的，偏度系数为0。较大的正值表明该分布具有右侧较长尾部。较大的负值表明有左侧较长尾部\n",
    "def skew_X(X):\n",
    "    skewness = skew(X)\n",
    "    return skewness\n",
    "\n",
    "#峰度系数（Kurtosis）用来度量数据在中心聚集程度。在正态分布情况下，峰度系数值是3。\n",
    "#>3的峰度系数说明观察量更集中，有比正态分布更短的尾部；\n",
    "#<3的峰度系数说明观测量不那么集中，有比正态分布更长的尾部，类似于矩形的均匀分布。\n",
    "def kurs_X(X):\n",
    "    kurs = kurtosis(X)\n",
    "    return kurs\n",
    "\n",
    "#常用均方根值来分析噪声\n",
    "def rms_X(X):\n",
    "    RMS = np.sqrt((np.sum(np.square(X))) * 1.0 / len(X))\n",
    "    return RMS\n",
    "\n",
    "def peak_X(X):\n",
    "    Peak = np.max([np.abs(max_X(X)), np.abs(min_X(X))])\n",
    "    return Peak\n",
    "\n",
    "#峰均比\n",
    "def papr_X(X):\n",
    "    Peak = peak_X(X)\n",
    "    RMS = rms_X(X)\n",
    "    PAPR = np.square(Peak) * 1.0 / np.square(RMS)\n",
    "    return PAPR\n",
    "\n",
    "'''\n",
    "计算时域10个bin特征\n",
    "'''\n",
    "def filter_X(X):\n",
    "    X_new = []\n",
    "    length = np.shape(X)[0]\n",
    "    for i in range(1, length):\n",
    "        if i != 0 and np.array_equal(X[i], X[i-1]):\n",
    "            continue\n",
    "        X_new.append(X[i])\n",
    "    return X_new\n",
    "\n",
    "\n",
    "#求X中所有的极大值和极小值点\n",
    "def minmax_cal(X):\n",
    "    length = np.shape(X)[0]\n",
    "    min_value = []\n",
    "    min_index = []\n",
    "    max_value = []\n",
    "    max_index = []\n",
    "    first = ''\n",
    "    for i in range(1, length-1):\n",
    "        if np.any(X[i] < X[i-1]) and np.any(X[i] < X[i+1]):\n",
    "            min_value.append(X[i])\n",
    "            min_index.append(i)\n",
    "        if np.any(X[i] > X[i-1]) and np.any(X[i] > X[i+1]):\n",
    "            max_value.append(X[i])\n",
    "            max_index.append(i)\n",
    "    if len(min_index) and len(max_index):       \n",
    "        if max_index[0] > min_index[0]:\n",
    "            first = 'min'\n",
    "        else:\n",
    "            first = 'max'\n",
    "        return min_value, max_value, first\n",
    "    else:\n",
    "        return [],[],[]\n",
    "\n",
    "\n",
    "#计算所有的极大值和极小值的差值        \n",
    "def minmax_sub_cal(X):\n",
    "    min_value, max_value, first = minmax_cal(X)\n",
    "    if min_value and max_value and first:\n",
    "        max_length = np.shape(max_value)[0]\n",
    "        sub = []\n",
    "        if first == 'min':\n",
    "            for i in range(max_length-1):\n",
    "                sub.append(max_value[i] - min_value[i])\n",
    "                sub.append(max_value[i] - min_value[i+1])\n",
    "        else:\n",
    "            for i in range(1, max_length-1):\n",
    "                sub.append(max_value[i] - min_value[i-1])\n",
    "                sub.append(max_value[i] - min_value[i])   \n",
    "        return sub\n",
    "    else:\n",
    "        return None     \n",
    "\n",
    "#计算极大极小值差值占比            \n",
    "def minmax_percent_cal(X, step=10):  \n",
    "    X = filter_X(X)\n",
    "    sub = minmax_sub_cal(X)\n",
    "    if sub:\n",
    "        length = int(np.shape(sub)[0])\n",
    "        max_value = np.max(sub)\n",
    "        min_value = np.min(sub)\n",
    "        diff = max_value - min_value\n",
    "        value = diff / step\n",
    "        nums = []\n",
    "        sub = np.array(sub)\n",
    "        for i in range(step):\n",
    "            scale_min = sub >= min_value + i * value\n",
    "            scale_max = sub < min_value + (i + 1) * value\n",
    "            scale = scale_min & scale_max\n",
    "            num = np.where(scale)[0]\n",
    "            size = np.shape(num)[0]\n",
    "            nums.append(size)\n",
    "        nums[-1] = nums[-1] + np.sum(sub == max_value)\n",
    "        per = np.array(nums, dtype=int) / length\n",
    "        return per\n",
    "    else:\n",
    "        return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "#非线性特征提取\n",
    "#采样频率为256Hz,则信号的最大频率为128Hz，进行5层小波分解\n",
    "def relativePower(X):\n",
    "    Ca5, Cd5, Cd4, Cd3, Cd2, Cd1 = pywt.wavedec(X, wavelet='db4', level=5)\n",
    "    min_length = min(len(Ca5), len(Cd5), len(Cd4), len(Cd3), len(Cd2), len(Cd1))\n",
    "    Ca5 = Ca5[:min_length]\n",
    "    Cd5 = Cd5[:min_length]\n",
    "    Cd4 = Cd4[:min_length]\n",
    "    Cd3 = Cd3[:min_length]\n",
    "    Cd2 = Cd2[:min_length]\n",
    "    Cd1 = Cd1[:min_length]\n",
    "    EA5 = sum([i*i for i in Ca5])\n",
    "    ED5 = sum([i*i for i in Cd5])\n",
    "    ED4 = sum([i*i for i in Cd4])\n",
    "    ED3 = sum([i*i for i in Cd3])\n",
    "    ED2 = sum([i*i for i in Cd2])\n",
    "    ED1 = sum([i*i for i in Cd1])\n",
    "    E = EA5 + ED5 + ED4 + ED3 + ED2 + ED1\n",
    "    pEA5 = EA5/E\n",
    "    pED5 = ED5/E\n",
    "    pED4 = ED4/E\n",
    "    pED3 = ED3/E\n",
    "    pED2 = ED2/E\n",
    "    pED1 = ED1/E\n",
    "    return pEA5, pED5, pED4, pED3, pED2, pED1\n",
    "\n",
    "#nonlinear analysis\n",
    "#小波熵\n",
    "def wavelet_entopy(X):\n",
    "    [pEA5, pED5, pED4, pED3, pED2, pED1] = relativePower(X)\n",
    "    wavelet_entopy = - (pEA5*math.log(pEA5) + pED5*math.log(pED5)\n",
    "    + pED4*math.log(pED4) + pED3*math.log(pED3) + pED2*math.log(pED2) + pED1*math.log(pED1))\n",
    "    return wavelet_entopy\n",
    "\n",
    "#计算Detrended Fluctuation Analysis值\n",
    "def DFA(X):\n",
    "    y = nolds.dfa(X)\n",
    "    return y\n",
    "\n",
    "#计算赫斯特指数\n",
    "def Hurst(X):\n",
    "    y = nolds.hurst_rs(X)\n",
    "    return y\n",
    "\n",
    "#计算Petrosian's Fractal Dimension分形维数值\n",
    "def Petrosian_FD(X):\n",
    "    D = np.diff(X)\n",
    "\n",
    "    delta = 0;\n",
    "    N = len(X)\n",
    "    #number of sign changes in signal\n",
    "    for i in range(1, len(D)):\n",
    "        if (D[i] * D[i-1] < 0).any() < 0:\n",
    "            delta += 1\n",
    "\n",
    "    feature = np.log10(N) / (np.log10(N) + np.log10(N / (N + 0.4 * delta)))\n",
    "\n",
    "    return feature\n",
    "\n",
    "#计算样本熵\n",
    "def sample_entropy(X):\n",
    "    y = nolds.sampen(X)\n",
    "    return y\n",
    "\n",
    "#计算排列熵\n",
    "#度量时间序列复杂性的一种方法,排列熵H的大小表征时间序列的随机程度，值越小说明该时间序列越规则，反之，该时间序列越具有随机性。\n",
    "def permutation_entropy(X):\n",
    "    y = ent.permutation_entropy(X, 4, 1)\n",
    "    return y\n",
    "\n",
    "#Hjorth Parameter: mobility and complexity\n",
    "def Hjorth(X):\n",
    "    D = np.diff(X)\n",
    "    D = list(D)\n",
    "    D.insert(0, X[0])\n",
    "    VarX = np.var(X)\n",
    "    VarD = np.var(D)\n",
    "    Mobility = np.sqrt(VarD / VarX)\n",
    "\n",
    "    DD = np.diff(D)\n",
    "    VarDD = np.var(DD)\n",
    "    Complexity = np.sqrt(VarDD / VarD) / Mobility\n",
    "\n",
    "    return Mobility, Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51277518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "           0         1         2         3             4          5   \\\n",
      "0   -0.000801  0.000832  0.000174 -0.000050  3.042424e-08   8.578171   \n",
      "1   -0.000649  0.000790  0.000160 -0.000024  2.561761e-08  10.775748   \n",
      "2   -0.000540  0.000710  0.000150 -0.000040  2.262825e-08   7.840534   \n",
      "3   -0.000639  0.000644  0.000149 -0.000067  2.225268e-08   8.700020   \n",
      "4   -0.000675  0.000575  0.000138  0.000028  1.915263e-08  14.234852   \n",
      "..        ...       ...       ...       ...           ...        ...   \n",
      "403 -0.000474  0.000695  0.000118 -0.000023  1.393997e-08   7.804528   \n",
      "404 -0.000172  0.000117  0.000039 -0.000009  1.494249e-09  13.147220   \n",
      "405 -0.000225  0.000121  0.000040 -0.000013  1.566719e-09   8.962627   \n",
      "406 -0.000354  0.000268  0.000053 -0.000012  2.847753e-09   5.717284   \n",
      "407 -0.000145  0.000270  0.000030  0.000003  9.245888e-10  10.008755   \n",
      "\n",
      "                                                    6   \\\n",
      "0    [-0.27699353382943975, 0.12261703240544874, 0....   \n",
      "1    [0.26886888894264205, 0.6235817762973523, 0.97...   \n",
      "2    [1.4284634629064963, 1.496144977121582, 1.4954...   \n",
      "3    [0.7132106854166381, 1.036996664826482, 1.1783...   \n",
      "4    [0.26571496879076556, 0.2530696426306982, 0.24...   \n",
      "..                                                 ...   \n",
      "403  [-0.17614376454318303, -0.21098583315403516, -...   \n",
      "404  [1.0315133316410874, 1.0342864849313147, 0.918...   \n",
      "405  [0.3421289264088778, 0.3165481123000982, 0.255...   \n",
      "406  [0.321151828009438, 0.11293787790718937, -0.08...   \n",
      "407  [-0.4972507974702745, -0.2458195728655469, -0....   \n",
      "\n",
      "                                                    7         8   \\\n",
      "0    [-0.9411355658436511, -1.0772750387775571, -0....  0.007109   \n",
      "1    [-1.1922997860052638, -0.05822608926814743, 1....  0.006342   \n",
      "2    [2.9633693823659053, 3.3760837601006397, 3.479...  0.006098   \n",
      "3    [1.6039457942734705, 2.149512485869784, 2.3725...  0.006404   \n",
      "4    [-0.9525240484822577, -0.9354776609915492, -0....  0.005539   \n",
      "..                                                 ...       ...   \n",
      "403  [0.30463528913296, 0.3093402149821438, 0.39934...  0.004717   \n",
      "404  [0.33350679768263625, 0.6630030372835951, 0.60...  0.001553   \n",
      "405  [-0.26461130161141533, -0.42102543251269786, -...  0.001629   \n",
      "406  [-0.07215431751594314, -0.062235784943994066, ...  0.002144   \n",
      "407  [-0.8166547624718183, -0.41109674225860715, -0...  0.001197   \n",
      "\n",
      "                                                    9   \\\n",
      "0    [-5.904910158814962e-05, -5.516004209741326e-0...   \n",
      "1    [-6.016082941498132e-05, -4.8544965451243204e-...   \n",
      "2    [-6.149038218421554e-06, -1.8922420818935992e-...   \n",
      "3    [-1.7017578963422614e-05, -2.2429469060478235e...   \n",
      "4    [1.6788824539962704e-05, 1.5372895744571498e-0...   \n",
      "..                                                 ...   \n",
      "403  [-5.759662354240435e-05, -6.699456938824723e-0...   \n",
      "404  [1.2532228212947193e-07, -1.7499661020736479e-...   \n",
      "405  [7.634116100849224e-07, 2.583421824829059e-06,...   \n",
      "406  [4.401702967102434e-05, 4.584309500639433e-05,...   \n",
      "407  [1.6231698340840417e-05, 2.1574877134723595e-0...   \n",
      "\n",
      "                                                    10  \\\n",
      "0    [-1.2317600501152602e-05, -1.5535651543368803e...   \n",
      "1    [-1.718409571006223e-05, -1.0105657649111759e-...   \n",
      "2    [1.6870293839648847e-05, 7.550861219081271e-06...   \n",
      "3    [1.1137297852296926e-05, 3.3641523937378185e-0...   \n",
      "4    [5.4253870430858e-05, 5.0963594215141915e-05, ...   \n",
      "..                                                 ...   \n",
      "403  [4.1749782334613815e-05, 4.256697489678128e-05...   \n",
      "404  [6.0072254229865104e-06, 1.1789891807914952e-0...   \n",
      "405  [1.9670405835358053e-05, 2.1327897864578254e-0...   \n",
      "406  [2.8432156789955132e-05, 2.2363239711309944e-0...   \n",
      "407  [5.382907921639179e-07, -6.40976370760381e-06,...   \n",
      "\n",
      "                                                    11  \\\n",
      "0    [8.587990711531557e-05, 7.817141825637701e-05,...   \n",
      "1    [5.4408066169249115e-05, 6.262275820775141e-05...   \n",
      "2    [5.543199674026459e-05, 5.267992079234639e-05,...   \n",
      "3    [-2.715499843103106e-05, -2.739899636289848e-0...   \n",
      "4    [2.4239931729526052e-06, -1.0987921763376171e-...   \n",
      "..                                                 ...   \n",
      "403  [-2.9462572623088944e-05, -2.372347997691688e-...   \n",
      "404  [-1.076446743587213e-05, -1.2009817031065404e-...   \n",
      "405  [-2.488866809851994e-05, -3.1190949161423454e-...   \n",
      "406  [-4.357598134299683e-05, -4.5157748784965443e-...   \n",
      "407  [-2.1465931864347157e-05, -1.9640199553111948e...   \n",
      "\n",
      "                                                    12  \\\n",
      "0    [5.6619587021865675e-05, 8.877675599880508e-05...   \n",
      "1    [-1.777126953659769e-05, -1.9547314299449898e-...   \n",
      "2    [2.5867377226162e-05, 3.485840429323367e-05, 4...   \n",
      "3    [-5.109958636811959e-05, -5.968486655048232e-0...   \n",
      "4    [3.556571502498813e-05, 2.940855791730076e-05,...   \n",
      "..                                                 ...   \n",
      "403  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "404  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "405  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "406  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "407  [-2.6234746232243397e-05, -2.7036990588707788e...   \n",
      "\n",
      "                                                    13  \\\n",
      "0    [-2.9982747114635e-05, -2.757319447262398e-05,...   \n",
      "1    [-4.721341668011744e-05, -3.230231693551837e-0...   \n",
      "2    [-1.5638316126589422e-05, -2.888737338787762e-...   \n",
      "3    [-2.386841764963893e-05, -3.5003630841727675e-...   \n",
      "4    [-3.276751027392353e-05, -3.739452859121711e-0...   \n",
      "..                                                 ...   \n",
      "403  [3.1301344000533616e-05, 2.885027263216688e-05...   \n",
      "404  [-4.450892441426342e-06, -1.9671336823803675e-...   \n",
      "405  [-2.4068708600456568e-05, -2.185657943160128e-...   \n",
      "406  [8.394749752443597e-07, 3.5036615849431496e-06...   \n",
      "407  [8.596293782647415e-06, 8.52679497020233e-06, ...   \n",
      "\n",
      "                                                    14  \\\n",
      "0    [-1.4292194225471806e-05, -1.4066963071560911e...   \n",
      "1    [-1.3407063742572212e-05, -4.342151202851052e-...   \n",
      "2    [3.1651293094523436e-05, 2.2849182842424843e-0...   \n",
      "3    [3.678297195129355e-05, 3.346265505347806e-05,...   \n",
      "4    [3.7985491526811965e-05, 3.5494669388697524e-0...   \n",
      "..                                                 ...   \n",
      "403  [-1.4199657676697095e-05, -1.3604983800015446e...   \n",
      "404  [-3.9218912768563924e-06, -4.542566593582727e-...   \n",
      "405  [2.386971476141171e-05, 2.504073987934668e-05,...   \n",
      "406  [4.50480762948839e-05, 4.410514887080812e-05, ...   \n",
      "407  [-2.427749041212526e-06, -1.654792953994881e-0...   \n",
      "\n",
      "                                                    15  \\\n",
      "0    [8.023492048325478e-05, 6.693754885510137e-05,...   \n",
      "1    [-2.3970169089407207e-07, 1.0738012449672521e-...   \n",
      "2    [8.709274482421358e-06, -5.922246021977795e-06...   \n",
      "3    [-4.035594898430251e-05, -4.028694309879329e-0...   \n",
      "4    [5.186048769164186e-06, 1.5573959303344626e-06...   \n",
      "..                                                 ...   \n",
      "403  [-8.27498776699268e-06, -1.0751224147115812e-0...   \n",
      "404  [-1.736828235709811e-05, -1.855912454410399e-0...   \n",
      "405  [-6.9936927219287045e-06, -6.707060963140874e-...   \n",
      "406  [-1.9561351420094492e-05, -2.5070402063148754e...   \n",
      "407  [-9.39986909039383e-06, -5.719366194474e-06, -...   \n",
      "\n",
      "                                                    16        17   18  \\\n",
      "0    [-9.872297433063827e-05, -6.553786002535789e-0...  2.038125  1.0   \n",
      "1    [5.085132860613835e-05, 5.190466925566037e-05,...  1.998033  1.0   \n",
      "2    [6.126924622270238e-05, 6.113272088320787e-05,...  2.132910  1.0   \n",
      "3    [-8.37174635630085e-05, -8.828632095740768e-05...  2.104078  1.0   \n",
      "4    [-5.5200814057977095e-05, -5.544742337390763e-...  1.949639  1.0   \n",
      "..                                                 ...       ...  ...   \n",
      "403  [1.4006866968910024e-05, 1.0604491587881747e-0...  1.905757  1.0   \n",
      "404  [2.142053120211203e-05, 1.9441316857585277e-05...  1.994479  1.0   \n",
      "405  [-1.916863777275984e-05, -2.4979206603879806e-...  2.081328  1.0   \n",
      "406  [-5.62502425355423e-06, -8.607454349875137e-06...  2.115279  1.0   \n",
      "407  [-1.4352159199299916e-05, -1.2504440220024798e...  1.998892  1.0   \n",
      "\n",
      "           19  \n",
      "0    1.742246  \n",
      "1    1.838045  \n",
      "2    1.883767  \n",
      "3    1.880255  \n",
      "4    1.839184  \n",
      "..        ...  \n",
      "403  1.612260  \n",
      "404  1.813342  \n",
      "405  1.775888  \n",
      "406  1.762679  \n",
      "407  1.664770  \n",
      "\n",
      "[408 rows x 20 columns]\n",
      "Labels:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "Column 0: Type = <class 'numpy.float64'>\n",
      "Column 1: Type = <class 'numpy.float64'>\n",
      "Column 2: Type = <class 'numpy.float64'>\n",
      "Column 3: Type = <class 'numpy.float64'>\n",
      "Column 4: Type = <class 'numpy.float64'>\n",
      "Column 5: Type = <class 'numpy.float64'>\n",
      "Column 6: Type = <class 'numpy.float64'>\n",
      "Column 7: Type = <class 'numpy.float64'>\n",
      "Column 8: Type = <class 'numpy.float64'>\n",
      "Column 9: Type = <class 'numpy.float64'>\n",
      "Column 10: Type = <class 'numpy.float64'>\n",
      "Column 11: Type = <class 'numpy.float64'>\n",
      "Column 12: Type = <class 'numpy.float64'>\n",
      "Column 13: Type = <class 'numpy.float64'>\n",
      "Column 14: Type = <class 'numpy.float64'>\n",
      "Column 15: Type = <class 'numpy.float64'>\n",
      "Column 16: Type = <class 'numpy.float64'>\n",
      "Column 17: Type = <class 'numpy.float64'>\n",
      "Column 18: Type = <class 'numpy.float64'>\n",
      "Column 19: Type = <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extract_features(X):\n",
    "    features = []\n",
    "    features.append(min_X(X))\n",
    "    features.append(max_X(X))\n",
    "    features.append(std_X(X))\n",
    "    features.append(mean_X(X))\n",
    "    features.append(var_X(X))\n",
    "    features.append(totalVariation(X))\n",
    "    features.append(skew_X(X))\n",
    "    features.append(kurs_X(X))\n",
    "    features.append(rms_X(X))\n",
    "    min_value, max_value, first = minmax_cal(X)\n",
    "\n",
    "    if min_value is None or max_value is None:\n",
    "        return None\n",
    "    \n",
    "    if len(min_value) != len(max_value):\n",
    "        return None\n",
    "    \n",
    "    features.extend(min_value)\n",
    "    features.extend(max_value)\n",
    "    features.append(first)\n",
    "    features.append(peak_X(X))\n",
    "    features.append(papr_X(X))\n",
    "\n",
    "    # Call minmax_percent_cal function and add its individual elements to features\n",
    "    sub = minmax_percent_cal(X)\n",
    "    features.extend(sub)\n",
    "\n",
    "    # Fill missing features with zeros\n",
    "    while len(features) < 17:\n",
    "        features.append(0)\n",
    "\n",
    "    # Truncate excess features\n",
    "    features = features[:17]\n",
    "\n",
    "    features.append(DFA(X))\n",
    "    features.append(Petrosian_FD(X))\n",
    "    features.append(sample_entropy(X))\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# 滤波后样本文件夹路径\n",
    "filtered_positive_folder = r'D:\\Epilepsy\\filtered_positive'\n",
    "filtered_negative_folder = r'D:\\Epilepsy\\filtered_negative'\n",
    "\n",
    "# 定义存储特征向量和标签的列表\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# 遍历滤波后样本文件夹（正样本）\n",
    "for file in os.listdir(filtered_positive_folder):\n",
    "    if file.endswith('.npy'):\n",
    "        # 加载滤波后的样本数据\n",
    "        file_path = os.path.join(filtered_positive_folder, file)\n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        # 应用特征提取函数获取特征\n",
    "        features = extract_features(data)\n",
    "        \n",
    "        # 检查特征向量是否为特殊值\n",
    "        if features is None:\n",
    "            # 特征向量不和谐，跳过这条数据\n",
    "            continue\n",
    "        \n",
    "        # 添加特征向量和标签到列表中\n",
    "        X.append(features)\n",
    "        y.append(1)  # 正样本的标签为 1\n",
    "\n",
    "# 遍历滤波后样本文件夹（负样本）\n",
    "for file in os.listdir(filtered_negative_folder):\n",
    "    if file.endswith('.npy'):\n",
    "        # 加载滤波后的样本数据\n",
    "        file_path = os.path.join(filtered_negative_folder, file)\n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        # 应用特征提取函数获取特征\n",
    "        features = extract_features(data)\n",
    "        \n",
    "        # 检查特征向量是否为特殊值\n",
    "        if features is None:\n",
    "            # 特征向量不和谐，跳过这条数据\n",
    "            continue\n",
    "        \n",
    "        # 添加特征向量和标签到列表中\n",
    "        X.append(features)\n",
    "        y.append(0)  # 负样本的标签为 0\n",
    "\n",
    "# 将特征向量列表转换为DataFrame\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "# 转换标签列表为NumPy数组\n",
    "y = np.array(y)\n",
    "\n",
    "# 打印特征向量和标签\n",
    "print(\"Features:\")\n",
    "print(X)\n",
    "print(\"Labels:\")\n",
    "print(y)\n",
    "\n",
    "# 检查每一列的特征值类型\n",
    "for column in range(len(features)):\n",
    "    column_values = [row[column] for row in data]\n",
    "    column_type = type(column_values[0])\n",
    "    print(f\"Column {column}: Type = {column_type}\")\n",
    "\n",
    "# 将特征向量 X 和标签 y 保存为NumPy数组\n",
    "X.to_numpy().dump('features.npy')\n",
    "np.save('labels.npy', y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66818eb5",
   "metadata": {},
   "source": [
    "### 归一化特征矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cf4fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0: Type = <class 'float'>, Shape = ()\n",
      "Column 1: Type = <class 'float'>, Shape = ()\n",
      "Column 2: Type = <class 'float'>, Shape = ()\n",
      "Column 3: Type = <class 'float'>, Shape = ()\n",
      "Column 4: Type = <class 'float'>, Shape = ()\n",
      "Column 5: Type = <class 'float'>, Shape = ()\n",
      "Column 6: Type = <class 'numpy.ndarray'>, Shape = (1537,)\n",
      "Column 7: Type = <class 'numpy.ndarray'>, Shape = (1537,)\n",
      "Column 8: Type = <class 'float'>, Shape = ()\n",
      "Column 9: Type = <class 'numpy.ndarray'>, Shape = (1537,)\n",
      "Column 10: Type = <class 'numpy.ndarray'>, Shape = (1537,)\n",
      "Column 11: Type = <class 'numpy.ndarray'>, Shape = (1537,)\n",
      "Column 12: Type = <class 'numpy.ndarray'>, Shape = (1537,)\n",
      "Column 13: Type = <class 'numpy.ndarray'>, Shape = (1537,)\n",
      "Column 14: Type = <class 'numpy.ndarray'>, Shape = (1537,)\n",
      "Column 15: Type = <class 'numpy.ndarray'>, Shape = (1537,)\n",
      "Column 16: Type = <class 'numpy.ndarray'>, Shape = (1537,)\n",
      "Column 17: Type = <class 'float'>, Shape = ()\n",
      "Column 18: Type = <class 'float'>, Shape = ()\n",
      "Column 19: Type = <class 'float'>, Shape = ()\n",
      "Row 0: Shape = (20,)\n",
      "Row 1: Shape = (20,)\n",
      "Row 2: Shape = (20,)\n",
      "Row 3: Shape = (20,)\n",
      "Row 4: Shape = (20,)\n",
      "Row 5: Shape = (20,)\n",
      "Row 6: Shape = (20,)\n",
      "Row 7: Shape = (20,)\n",
      "Row 8: Shape = (20,)\n",
      "Row 9: Shape = (20,)\n",
      "Row 10: Shape = (20,)\n",
      "Row 11: Shape = (20,)\n",
      "Row 12: Shape = (20,)\n",
      "Row 13: Shape = (20,)\n",
      "Row 14: Shape = (20,)\n",
      "Row 15: Shape = (20,)\n",
      "Row 16: Shape = (20,)\n",
      "Row 17: Shape = (20,)\n",
      "Row 18: Shape = (20,)\n",
      "Row 19: Shape = (20,)\n",
      "Row 20: Shape = (20,)\n",
      "Row 21: Shape = (20,)\n",
      "Row 22: Shape = (20,)\n",
      "Row 23: Shape = (20,)\n",
      "Row 24: Shape = (20,)\n",
      "Row 25: Shape = (20,)\n",
      "Row 26: Shape = (20,)\n",
      "Row 27: Shape = (20,)\n",
      "Row 28: Shape = (20,)\n",
      "Row 29: Shape = (20,)\n",
      "Row 30: Shape = (20,)\n",
      "Row 31: Shape = (20,)\n",
      "Row 32: Shape = (20,)\n",
      "Row 33: Shape = (20,)\n",
      "Row 34: Shape = (20,)\n",
      "Row 35: Shape = (20,)\n",
      "Row 36: Shape = (20,)\n",
      "Row 37: Shape = (20,)\n",
      "Row 38: Shape = (20,)\n",
      "Row 39: Shape = (20,)\n",
      "Row 40: Shape = (20,)\n",
      "Row 41: Shape = (20,)\n",
      "Row 42: Shape = (20,)\n",
      "Row 43: Shape = (20,)\n",
      "Row 44: Shape = (20,)\n",
      "Row 45: Shape = (20,)\n",
      "Row 46: Shape = (20,)\n",
      "Row 47: Shape = (20,)\n",
      "Row 48: Shape = (20,)\n",
      "Row 49: Shape = (20,)\n",
      "Row 50: Shape = (20,)\n",
      "Row 51: Shape = (20,)\n",
      "Row 52: Shape = (20,)\n",
      "Row 53: Shape = (20,)\n",
      "Row 54: Shape = (20,)\n",
      "Row 55: Shape = (20,)\n",
      "Row 56: Shape = (20,)\n",
      "Row 57: Shape = (20,)\n",
      "Row 58: Shape = (20,)\n",
      "Row 59: Shape = (20,)\n",
      "Row 60: Shape = (20,)\n",
      "Row 61: Shape = (20,)\n",
      "Row 62: Shape = (20,)\n",
      "Row 63: Shape = (20,)\n",
      "Row 64: Shape = (20,)\n",
      "Row 65: Shape = (20,)\n",
      "Row 66: Shape = (20,)\n",
      "Row 67: Shape = (20,)\n",
      "Row 68: Shape = (20,)\n",
      "Row 69: Shape = (20,)\n",
      "Row 70: Shape = (20,)\n",
      "Row 71: Shape = (20,)\n",
      "Row 72: Shape = (20,)\n",
      "Row 73: Shape = (20,)\n",
      "Row 74: Shape = (20,)\n",
      "Row 75: Shape = (20,)\n",
      "Row 76: Shape = (20,)\n",
      "Row 77: Shape = (20,)\n",
      "Row 78: Shape = (20,)\n",
      "Row 79: Shape = (20,)\n",
      "Row 80: Shape = (20,)\n",
      "Row 81: Shape = (20,)\n",
      "Row 82: Shape = (20,)\n",
      "Row 83: Shape = (20,)\n",
      "Row 84: Shape = (20,)\n",
      "Row 85: Shape = (20,)\n",
      "Row 86: Shape = (20,)\n",
      "Row 87: Shape = (20,)\n",
      "Row 88: Shape = (20,)\n",
      "Row 89: Shape = (20,)\n",
      "Row 90: Shape = (20,)\n",
      "Row 91: Shape = (20,)\n",
      "Row 92: Shape = (20,)\n",
      "Row 93: Shape = (20,)\n",
      "Row 94: Shape = (20,)\n",
      "Row 95: Shape = (20,)\n",
      "Row 96: Shape = (20,)\n",
      "Row 97: Shape = (20,)\n",
      "Row 98: Shape = (20,)\n",
      "Row 99: Shape = (20,)\n",
      "Row 100: Shape = (20,)\n",
      "Row 101: Shape = (20,)\n",
      "Row 102: Shape = (20,)\n",
      "Row 103: Shape = (20,)\n",
      "Row 104: Shape = (20,)\n",
      "Row 105: Shape = (20,)\n",
      "Row 106: Shape = (20,)\n",
      "Row 107: Shape = (20,)\n",
      "Row 108: Shape = (20,)\n",
      "Row 109: Shape = (20,)\n",
      "Row 110: Shape = (20,)\n",
      "Row 111: Shape = (20,)\n",
      "Row 112: Shape = (20,)\n",
      "Row 113: Shape = (20,)\n",
      "Row 114: Shape = (20,)\n",
      "Row 115: Shape = (20,)\n",
      "Row 116: Shape = (20,)\n",
      "Row 117: Shape = (20,)\n",
      "Row 118: Shape = (20,)\n",
      "Row 119: Shape = (20,)\n",
      "Row 120: Shape = (20,)\n",
      "Row 121: Shape = (20,)\n",
      "Row 122: Shape = (20,)\n",
      "Row 123: Shape = (20,)\n",
      "Row 124: Shape = (20,)\n",
      "Row 125: Shape = (20,)\n",
      "Row 126: Shape = (20,)\n",
      "Row 127: Shape = (20,)\n",
      "Row 128: Shape = (20,)\n",
      "Row 129: Shape = (20,)\n",
      "Row 130: Shape = (20,)\n",
      "Row 131: Shape = (20,)\n",
      "Row 132: Shape = (20,)\n",
      "Row 133: Shape = (20,)\n",
      "Row 134: Shape = (20,)\n",
      "Row 135: Shape = (20,)\n",
      "Row 136: Shape = (20,)\n",
      "Row 137: Shape = (20,)\n",
      "Row 138: Shape = (20,)\n",
      "Row 139: Shape = (20,)\n",
      "Row 140: Shape = (20,)\n",
      "Row 141: Shape = (20,)\n",
      "Row 142: Shape = (20,)\n",
      "Row 143: Shape = (20,)\n",
      "Row 144: Shape = (20,)\n",
      "Row 145: Shape = (20,)\n",
      "Row 146: Shape = (20,)\n",
      "Row 147: Shape = (20,)\n",
      "Row 148: Shape = (20,)\n",
      "Row 149: Shape = (20,)\n",
      "Row 150: Shape = (20,)\n",
      "Row 151: Shape = (20,)\n",
      "Row 152: Shape = (20,)\n",
      "Row 153: Shape = (20,)\n",
      "Row 154: Shape = (20,)\n",
      "Row 155: Shape = (20,)\n",
      "Row 156: Shape = (20,)\n",
      "Row 157: Shape = (20,)\n",
      "Row 158: Shape = (20,)\n",
      "Row 159: Shape = (20,)\n",
      "Row 160: Shape = (20,)\n",
      "Row 161: Shape = (20,)\n",
      "Row 162: Shape = (20,)\n",
      "Row 163: Shape = (20,)\n",
      "Row 164: Shape = (20,)\n",
      "Row 165: Shape = (20,)\n",
      "Row 166: Shape = (20,)\n",
      "Row 167: Shape = (20,)\n",
      "Row 168: Shape = (20,)\n",
      "Row 169: Shape = (20,)\n",
      "Row 170: Shape = (20,)\n",
      "Row 171: Shape = (20,)\n",
      "Row 172: Shape = (20,)\n",
      "Row 173: Shape = (20,)\n",
      "Row 174: Shape = (20,)\n",
      "Row 175: Shape = (20,)\n",
      "Row 176: Shape = (20,)\n",
      "Row 177: Shape = (20,)\n",
      "Row 178: Shape = (20,)\n",
      "Row 179: Shape = (20,)\n",
      "Row 180: Shape = (20,)\n",
      "Row 181: Shape = (20,)\n",
      "Row 182: Shape = (20,)\n",
      "Row 183: Shape = (20,)\n",
      "Row 184: Shape = (20,)\n",
      "Row 185: Shape = (20,)\n",
      "Row 186: Shape = (20,)\n",
      "Row 187: Shape = (20,)\n",
      "Row 188: Shape = (20,)\n",
      "Row 189: Shape = (20,)\n",
      "Row 190: Shape = (20,)\n",
      "Row 191: Shape = (20,)\n",
      "Row 192: Shape = (20,)\n",
      "Row 193: Shape = (20,)\n",
      "Row 194: Shape = (20,)\n",
      "Row 195: Shape = (20,)\n",
      "Row 196: Shape = (20,)\n",
      "Row 197: Shape = (20,)\n",
      "Row 198: Shape = (20,)\n",
      "Row 199: Shape = (20,)\n",
      "Row 200: Shape = (20,)\n",
      "Row 201: Shape = (20,)\n",
      "Row 202: Shape = (20,)\n",
      "Row 203: Shape = (20,)\n",
      "Row 204: Shape = (20,)\n",
      "Row 205: Shape = (20,)\n",
      "Row 206: Shape = (20,)\n",
      "Row 207: Shape = (20,)\n",
      "Row 208: Shape = (20,)\n",
      "Row 209: Shape = (20,)\n",
      "Row 210: Shape = (20,)\n",
      "Row 211: Shape = (20,)\n",
      "Row 212: Shape = (20,)\n",
      "Row 213: Shape = (20,)\n",
      "Row 214: Shape = (20,)\n",
      "Row 215: Shape = (20,)\n",
      "Row 216: Shape = (20,)\n",
      "Row 217: Shape = (20,)\n",
      "Row 218: Shape = (20,)\n",
      "Row 219: Shape = (20,)\n",
      "Row 220: Shape = (20,)\n",
      "Row 221: Shape = (20,)\n",
      "Row 222: Shape = (20,)\n",
      "Row 223: Shape = (20,)\n",
      "Row 224: Shape = (20,)\n",
      "Row 225: Shape = (20,)\n",
      "Row 226: Shape = (20,)\n",
      "Row 227: Shape = (20,)\n",
      "Row 228: Shape = (20,)\n",
      "Row 229: Shape = (20,)\n",
      "Row 230: Shape = (20,)\n",
      "Row 231: Shape = (20,)\n",
      "Row 232: Shape = (20,)\n",
      "Row 233: Shape = (20,)\n",
      "Row 234: Shape = (20,)\n",
      "Row 235: Shape = (20,)\n",
      "Row 236: Shape = (20,)\n",
      "Row 237: Shape = (20,)\n",
      "Row 238: Shape = (20,)\n",
      "Row 239: Shape = (20,)\n",
      "Row 240: Shape = (20,)\n",
      "Row 241: Shape = (20,)\n",
      "Row 242: Shape = (20,)\n",
      "Row 243: Shape = (20,)\n",
      "Row 244: Shape = (20,)\n",
      "Row 245: Shape = (20,)\n",
      "Row 246: Shape = (20,)\n",
      "Row 247: Shape = (20,)\n",
      "Row 248: Shape = (20,)\n",
      "Row 249: Shape = (20,)\n",
      "Row 250: Shape = (20,)\n",
      "Row 251: Shape = (20,)\n",
      "Row 252: Shape = (20,)\n",
      "Row 253: Shape = (20,)\n",
      "Row 254: Shape = (20,)\n",
      "Row 255: Shape = (20,)\n",
      "Row 256: Shape = (20,)\n",
      "Row 257: Shape = (20,)\n",
      "Row 258: Shape = (20,)\n",
      "Row 259: Shape = (20,)\n",
      "Row 260: Shape = (20,)\n",
      "Row 261: Shape = (20,)\n",
      "Row 262: Shape = (20,)\n",
      "Row 263: Shape = (20,)\n",
      "Row 264: Shape = (20,)\n",
      "Row 265: Shape = (20,)\n",
      "Row 266: Shape = (20,)\n",
      "Row 267: Shape = (20,)\n",
      "Row 268: Shape = (20,)\n",
      "Row 269: Shape = (20,)\n",
      "Row 270: Shape = (20,)\n",
      "Row 271: Shape = (20,)\n",
      "Row 272: Shape = (20,)\n",
      "Row 273: Shape = (20,)\n",
      "Row 274: Shape = (20,)\n",
      "Row 275: Shape = (20,)\n",
      "Row 276: Shape = (20,)\n",
      "Row 277: Shape = (20,)\n",
      "Row 278: Shape = (20,)\n",
      "Row 279: Shape = (20,)\n",
      "Row 280: Shape = (20,)\n",
      "Row 281: Shape = (20,)\n",
      "Row 282: Shape = (20,)\n",
      "Row 283: Shape = (20,)\n",
      "Row 284: Shape = (20,)\n",
      "Row 285: Shape = (20,)\n",
      "Row 286: Shape = (20,)\n",
      "Row 287: Shape = (20,)\n",
      "Row 288: Shape = (20,)\n",
      "Row 289: Shape = (20,)\n",
      "Row 290: Shape = (20,)\n",
      "Row 291: Shape = (20,)\n",
      "Row 292: Shape = (20,)\n",
      "Row 293: Shape = (20,)\n",
      "Row 294: Shape = (20,)\n",
      "Row 295: Shape = (20,)\n",
      "Row 296: Shape = (20,)\n",
      "Row 297: Shape = (20,)\n",
      "Row 298: Shape = (20,)\n",
      "Row 299: Shape = (20,)\n",
      "Row 300: Shape = (20,)\n",
      "Row 301: Shape = (20,)\n",
      "Row 302: Shape = (20,)\n",
      "Row 303: Shape = (20,)\n",
      "Row 304: Shape = (20,)\n",
      "Row 305: Shape = (20,)\n",
      "Row 306: Shape = (20,)\n",
      "Row 307: Shape = (20,)\n",
      "Row 308: Shape = (20,)\n",
      "Row 309: Shape = (20,)\n",
      "Row 310: Shape = (20,)\n",
      "Row 311: Shape = (20,)\n",
      "Row 312: Shape = (20,)\n",
      "Row 313: Shape = (20,)\n",
      "Row 314: Shape = (20,)\n",
      "Row 315: Shape = (20,)\n",
      "Row 316: Shape = (20,)\n",
      "Row 317: Shape = (20,)\n",
      "Row 318: Shape = (20,)\n",
      "Row 319: Shape = (20,)\n",
      "Row 320: Shape = (20,)\n",
      "Row 321: Shape = (20,)\n",
      "Row 322: Shape = (20,)\n",
      "Row 323: Shape = (20,)\n",
      "Row 324: Shape = (20,)\n",
      "Row 325: Shape = (20,)\n",
      "Row 326: Shape = (20,)\n",
      "Row 327: Shape = (20,)\n",
      "Row 328: Shape = (20,)\n",
      "Row 329: Shape = (20,)\n",
      "Row 330: Shape = (20,)\n",
      "Row 331: Shape = (20,)\n",
      "Row 332: Shape = (20,)\n",
      "Row 333: Shape = (20,)\n",
      "Row 334: Shape = (20,)\n",
      "Row 335: Shape = (20,)\n",
      "Row 336: Shape = (20,)\n",
      "Row 337: Shape = (20,)\n",
      "Row 338: Shape = (20,)\n",
      "Row 339: Shape = (20,)\n",
      "Row 340: Shape = (20,)\n",
      "Row 341: Shape = (20,)\n",
      "Row 342: Shape = (20,)\n",
      "Row 343: Shape = (20,)\n",
      "Row 344: Shape = (20,)\n",
      "Row 345: Shape = (20,)\n",
      "Row 346: Shape = (20,)\n",
      "Row 347: Shape = (20,)\n",
      "Row 348: Shape = (20,)\n",
      "Row 349: Shape = (20,)\n",
      "Row 350: Shape = (20,)\n",
      "Row 351: Shape = (20,)\n",
      "Row 352: Shape = (20,)\n",
      "Row 353: Shape = (20,)\n",
      "Row 354: Shape = (20,)\n",
      "Row 355: Shape = (20,)\n",
      "Row 356: Shape = (20,)\n",
      "Row 357: Shape = (20,)\n",
      "Row 358: Shape = (20,)\n",
      "Row 359: Shape = (20,)\n",
      "Row 360: Shape = (20,)\n",
      "Row 361: Shape = (20,)\n",
      "Row 362: Shape = (20,)\n",
      "Row 363: Shape = (20,)\n",
      "Row 364: Shape = (20,)\n",
      "Row 365: Shape = (20,)\n",
      "Row 366: Shape = (20,)\n",
      "Row 367: Shape = (20,)\n",
      "Row 368: Shape = (20,)\n",
      "Row 369: Shape = (20,)\n",
      "Row 370: Shape = (20,)\n",
      "Row 371: Shape = (20,)\n",
      "Row 372: Shape = (20,)\n",
      "Row 373: Shape = (20,)\n",
      "Row 374: Shape = (20,)\n",
      "Row 375: Shape = (20,)\n",
      "Row 376: Shape = (20,)\n",
      "Row 377: Shape = (20,)\n",
      "Row 378: Shape = (20,)\n",
      "Row 379: Shape = (20,)\n",
      "Row 380: Shape = (20,)\n",
      "Row 381: Shape = (20,)\n",
      "Row 382: Shape = (20,)\n",
      "Row 383: Shape = (20,)\n",
      "Row 384: Shape = (20,)\n",
      "Row 385: Shape = (20,)\n",
      "Row 386: Shape = (20,)\n",
      "Row 387: Shape = (20,)\n",
      "Row 388: Shape = (20,)\n",
      "Row 389: Shape = (20,)\n",
      "Row 390: Shape = (20,)\n",
      "Row 391: Shape = (20,)\n",
      "Row 392: Shape = (20,)\n",
      "Row 393: Shape = (20,)\n",
      "Row 394: Shape = (20,)\n",
      "Row 395: Shape = (20,)\n",
      "Row 396: Shape = (20,)\n",
      "Row 397: Shape = (20,)\n",
      "Row 398: Shape = (20,)\n",
      "Row 399: Shape = (20,)\n",
      "Row 400: Shape = (20,)\n",
      "Row 401: Shape = (20,)\n",
      "Row 402: Shape = (20,)\n",
      "Row 403: Shape = (20,)\n",
      "Row 404: Shape = (20,)\n",
      "Row 405: Shape = (20,)\n",
      "Row 406: Shape = (20,)\n",
      "Row 407: Shape = (20,)\n",
      "[[-0.0008010994777823562 0.0008318179774890642 0.0001744254565313163 ...\n",
      "  2.0381252755584995 1.0 1.742246387566729]\n",
      " [-0.0006494387588177576 0.0007896890082214406 0.00016005500895307703 ...\n",
      "  1.99803269889615 1.0 1.8380451556293038]\n",
      " [-0.0005399801449382757 0.0007101973115427362 0.00015042689132673784 ...\n",
      "  2.132909722428233 1.0 1.8837671728866725]\n",
      " ...\n",
      " [-0.00022469244976564427 0.00012096017895111895 3.95818027446979e-05 ...\n",
      "  2.0813282187285176 1.0 1.7758884967771995]\n",
      " [-0.00035404707429268986 0.00026844031821403514 5.336434152296223e-05\n",
      "  ... 2.1152791842480014 1.0 1.7626788209620532]\n",
      " [-0.00014486524765928237 0.0002698868576823856 3.040705175166141e-05 ...\n",
      "  1.9988919453922214 1.0 1.6647696116468473]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 加载特征矩阵\n",
    "features = np.load('features.npy', allow_pickle=True)\n",
    "\n",
    "# 检查每一列的特征值类型和形状\n",
    "for i in range(features.shape[1]):\n",
    "    column = features[:, i]\n",
    "    column_type = type(column[0])\n",
    "    column_shape = np.shape(column[0])\n",
    "    print(f\"Column {i}: Type = {column_type}, Shape = {column_shape}\")\n",
    "    \n",
    "# 检查每一行的数组维度\n",
    "for i in range(features.shape[0]):\n",
    "    row = features[i, :]\n",
    "    print(f\"Row {i}: Shape = {np.shape(row)}\")\n",
    "\n",
    "# 最大-最小归一化\n",
    "normalized_features = np.copy(features)  # 创建一个归一化后的特征矩阵副本\n",
    "\n",
    "for i in range(features.shape[1]):\n",
    "    column = features[:, i]\n",
    "    \n",
    "    if isinstance(column[0], np.ndarray):\n",
    "        # 对多维度特征列进行归一化\n",
    "        column_min = np.min(np.concatenate(column))\n",
    "        column_max = np.max(np.concatenate(column))\n",
    "        normalized_column = [(x - column_min) / (column_max - column_min) for x in column]\n",
    "        normalized_features[:, i] = normalized_column\n",
    "    else:\n",
    "        # 单维度特征列不需要归一化\n",
    "        pass\n",
    "\n",
    "# 打印归一化后的特征矩阵\n",
    "print(normalized_features)\n",
    "\n",
    "# 保存归一化后的特征矩阵\n",
    "np.save('normalized_features.npy', normalized_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ff4cf",
   "metadata": {},
   "source": [
    "\n",
    "### 划分训练集和测试集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b29f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集特征矩阵形状： (326, 15380)\n",
      "训练集标签数组形状： (326,)\n",
      "测试集特征矩阵形状： (82, 15380)\n",
      "测试集标签数组形状： (82,)\n",
      "准确率： 0.5853658536585366\n",
      "精确度： 0.6571428571428571\n",
      "召回率： 0.5111111111111111\n",
      "F1值： 0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\python3.11.3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 加载特征矩阵和标签数组\n",
    "features = np.load('normalized_features.npy', allow_pickle=True)\n",
    "labels = np.load('labels.npy', allow_pickle=True)\n",
    "\n",
    "# 将多维数组展平为一维\n",
    "flattened_features = []\n",
    "for row in features:\n",
    "    flattened_row = []\n",
    "    for element in row:\n",
    "        if isinstance(element, np.ndarray):\n",
    "            flattened_row.extend(element.tolist())\n",
    "        else:\n",
    "            flattened_row.append(element)\n",
    "    flattened_features.append(flattened_row)\n",
    "\n",
    "# 转换为NumPy数组\n",
    "flattened_features = np.array(flattened_features)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(flattened_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 打印训练集和测试集的形状\n",
    "print(\"训练集特征矩阵形状：\", X_train.shape)\n",
    "print(\"训练集标签数组形状：\", y_train.shape)\n",
    "print(\"测试集特征矩阵形状：\", X_test.shape)\n",
    "print(\"测试集标签数组形状：\", y_test.shape)\n",
    "\n",
    "\n",
    "# 创建逻辑回归模型对象\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 使用训练集进行模型训练\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"准确率：\", accuracy)\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(y_test, predictions)\n",
    "print(\"精确度：\", precision)\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(y_test, predictions)\n",
    "print(\"召回率：\", recall)\n",
    "\n",
    "# 计算F1值\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(\"F1值：\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51bace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
